# ğŸ¯ L2Arctic ë°”ë¡œ ì‹¤í–‰ ê°€ì´ë“œ (ì—ëŸ¬ í•´ê²°ë¨)

## ğŸ“ ìµœì¢… íŒŒì¼ êµ¬ì¡° (src í´ë” ì—†ìŒ)

```
speechbrain_multitask/
â”œâ”€â”€ ğŸ“„ model.py                    # ë‹¨ìˆœí™”ëœ ëª¨ë¸ (HuggingFace ì§ì ‘ ì‚¬ìš©)
â”œâ”€â”€ ğŸ“„ train.py                    # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ (ë£¨íŠ¸ ë ˆë²¨)
â”œâ”€â”€ ğŸ“„ evaluate.py                 # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (ë£¨íŠ¸ ë ˆë²¨)  
â”œâ”€â”€ ğŸ“„ data_prepare.py             # ë°ì´í„° ì¤€ë¹„ (ë£¨íŠ¸ ë ˆë²¨)
â”œâ”€â”€ ğŸ“ hparams/
â”‚   â””â”€â”€ ğŸ“„ multitask.yaml         # ë‹¨ìˆœí™”ëœ ì„¤ì • (ì—ëŸ¬ í•´ê²°)
â””â”€â”€ ğŸ“ data/                      # L2Arctic ë°ì´í„°
    â”œâ”€â”€ ğŸ“„ train_data.json
    â”œâ”€â”€ ğŸ“„ val_data.json
    â”œâ”€â”€ ğŸ“„ eval.json
    â”œâ”€â”€ ğŸ“„ phoneme_to_id.json
    â””â”€â”€ ğŸ“ l2arctic_dataset/
```

## ğŸš€ ì¦‰ì‹œ ì‹¤í–‰ (ë³µì‚¬-ë¶™ì—¬ë„£ê¸°)

### 1. í™˜ê²½ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” (ì´ë¯¸ ìˆë‹¤ë©´)
source env/bin/activate  # ë˜ëŠ” conda activate your_env

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•œ ë²ˆë§Œ)
pip install torch torchaudio transformers speechbrain hyperpyyaml scikit-learn editdistance jiwer tqdm
```

### 2. ë°”ë¡œ í›ˆë ¨ ì‹¤í–‰! ğŸ”¥
```bash
# ê¸°ë³¸ í›ˆë ¨ (8GB+ GPU)
python train.py hparams/multitask.yaml --data_folder ./data --output_folder ./results --device cuda

# ë©”ëª¨ë¦¬ ì ˆì•½ (4-6GB GPU)
python -c "
with open('hparams/multitask.yaml', 'r') as f: config = f.read()
config = config.replace('batch_size: 8', 'batch_size: 4')
config = config.replace('hidden_dim: 1024', 'hidden_dim: 512')
with open('hparams/small.yaml', 'w') as f: f.write(config)
"
python train.py hparams/small.yaml --data_folder ./data --output_folder ./results --device cuda

# ì´ˆì†Œí˜• GPU (2-4GB)
python -c "
with open('hparams/multitask.yaml', 'r') as f: config = f.read()
config = config.replace('batch_size: 8', 'batch_size: 2')
config = config.replace('hidden_dim: 1024', 'hidden_dim: 256')
config = config.replace('num_workers: 4', 'num_workers: 1')
with open('hparams/mini.yaml', 'w') as f: f.write(config)
"
python train.py hparams/mini.yaml --data_folder ./data --output_folder ./results --device cuda

# CPU ëª¨ë“œ (GPU ì—†ìŒ)
python train.py hparams/multitask.yaml --data_folder ./data --output_folder ./results --device cpu
```

### 3. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (1 ì—í¬í¬)
```bash
python -c "
with open('hparams/multitask.yaml', 'r') as f: config = f.read()
config = config.replace('number_of_epochs: 30', 'number_of_epochs: 1')
config = config.replace('batch_size: 8', 'batch_size: 4')
with open('hparams/test.yaml', 'w') as f: f.write(config)
"
python train.py hparams/test.yaml --data_folder ./data --output_folder ./test_results --device cuda
```

## ğŸ“Š í›ˆë ¨ ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
```bash
# ì‹¤ì‹œê°„ ë¡œê·¸
tail -f results/save/train.log

# ìµœê³  ì„±ëŠ¥ í™•ì¸
grep "NEW BEST" results/save/train.log

# GPU ìƒíƒœ
watch -n 1 nvidia-smi

# ì—í¬í¬ë³„ ê²°ê³¼
ls results/save/epoch_*_stats.json
cat results/save/epoch_5_stats.json | python -m json.tool
```

## ğŸ“ˆ í‰ê°€ ì‹¤í–‰

### ìë™ í‰ê°€ (ìµœì‹  ì²´í¬í¬ì¸íŠ¸)
```bash
# ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ì•„ì„œ í‰ê°€
CHECKPOINT=$(find results/save -name "*.ckpt" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2-)
python evaluate.py hparams/multitask.yaml --model_checkpoint "$CHECKPOINT" --output_folder ./eval_results --device cuda

# ê²°ê³¼ í™•ì¸
cat eval_results/evaluation_summary.json | python -m json.tool
```

## ğŸ¯ ì„±ëŠ¥ í™•ì¸

### ìµœì¢… ê²°ê³¼ ìš”ì•½
```bash
python -c "
import os, json
if os.path.exists('eval_results/evaluation_summary.json'):
    with open('eval_results/evaluation_summary.json') as f:
        results = json.load(f)
    print('ğŸ¯ ìµœì¢… ì„±ëŠ¥:')
    for key, value in results.items():
        if isinstance(value, float):
            print(f'   {key}: {value:.4f}')
        else:
            print(f'   {key}: {value}')
else:
    print('âŒ í‰ê°€ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € evaluate.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.')
"
```

### ìƒ˜í”Œ ì˜ˆì¸¡ í™•ì¸
```bash
cat eval_results/sample_predictions.json | python -m json.tool | head -50
```

## ğŸ”§ ë¬¸ì œ í•´ê²°

### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸°ë¥¼ 1ë¡œ ì¤„ì´ê¸°
python -c "
with open('hparams/multitask.yaml', 'r') as f: config = f.read()
config = config.replace('batch_size: 8', 'batch_size: 1')
config = config.replace('eval_batch_size: 8', 'eval_batch_size: 1')
config = config.replace('hidden_dim: 1024', 'hidden_dim: 128')
config = config.replace('num_workers: 4', 'num_workers: 0')
with open('hparams/ultra_mini.yaml', 'w') as f: f.write(config)
"
python train.py hparams/ultra_mini.yaml --data_folder ./data --output_folder ./results --device cuda
```

### ë°ì´í„° ê²€ì¦
```bash
# ëˆ„ë½ íŒŒì¼ í™•ì¸
python -c "
import json, os
with open('data/train_data.json') as f: data = json.load(f)
missing = [item['wav'] for item in data.values() if not os.path.exists(item['wav'])]
print(f'ëˆ„ë½ëœ íŒŒì¼: {len(missing)}/{len(data)}ê°œ')
if missing[:3]: 
    print('ì˜ˆì‹œ:')
    for f in missing[:3]: print(f'  {f}')
if len(missing) == 0:
    print('âœ… ëª¨ë“  ìŒì„± íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤!')
"

# ìŒì†Œ ë§¤í•‘ í™•ì¸
python -c "
import json
with open('data/phoneme_to_id.json') as f: phonemes = json.load(f)
print(f'ìŒì†Œ ê°œìˆ˜: {len(phonemes)}')
print('ìƒ˜í”Œ:', dict(list(phonemes.items())[:5]))
"
```

### íŒ¨í‚¤ì§€ ë¬¸ì œ
```bash
# SpeechBrain ì¬ì„¤ì¹˜
pip uninstall speechbrain -y
pip install speechbrain

# Transformers ì—…ë°ì´íŠ¸
pip install --upgrade transformers

# ì „ì²´ ì¬ì„¤ì¹˜
pip install --force-reinstall torch torchaudio transformers speechbrain
```

## âš¡ ì„±ëŠ¥ ìµœì í™”

### GPU ë©”ëª¨ë¦¬ë³„ ê¶Œì¥ ì„¤ì •
```bash
# RTX 3060 (8GB)
python -c "
config = '''batch_size: 4
hidden_dim: 512
num_workers: 2'''
print('RTX 3060 ê¶Œì¥ ì„¤ì •:')
print(config)
"

# RTX 3070 (8GB)  
python -c "
config = '''batch_size: 6
hidden_dim: 768
num_workers: 4'''
print('RTX 3070 ê¶Œì¥ ì„¤ì •:')
print(config)
"

# RTX 3080 (10GB)
python -c "
config = '''batch_size: 8
hidden_dim: 1024
num_workers: 4'''
print('RTX 3080 ê¶Œì¥ ì„¤ì •:')
print(config)
"

# RTX 3090/4090 (24GB)
python -c "
config = '''batch_size: 16
hidden_dim: 1024
num_workers: 8'''
print('RTX 3090/4090 ê¶Œì¥ ì„¤ì •:')
print(config)
"
```

## ğŸ‰ ì„±ê³µ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ëª¨ë“  ê²ƒì´ ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
```bash
# 1ë‹¨ê³„: í™˜ê²½ í™•ì¸
python -c "import torch, transformers, speechbrain; print('âœ… ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨')"

# 2ë‹¨ê³„: ë°ì´í„° í™•ì¸  
python -c "
import json, os
files = ['data/train_data.json', 'data/val_data.json', 'data/eval.json', 'data/phoneme_to_id.json']
all_exist = all(os.path.exists(f) for f in files)
print('âœ… ëª¨ë“  ë°ì´í„° íŒŒì¼ ì¡´ì¬' if all_exist else 'âŒ ì¼ë¶€ ë°ì´í„° íŒŒì¼ ëˆ„ë½')
"

# 3ë‹¨ê³„: ë¹ ë¥¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸
python train.py hparams/test.yaml --data_folder ./data --output_folder ./test_results --device cuda

# 4ë‹¨ê³„: ê²°ê³¼ í™•ì¸
python -c "
import os
success = os.path.exists('test_results/save/train.log')
print('âœ… í…ŒìŠ¤íŠ¸ í›ˆë ¨ ì„±ê³µ!' if success else 'âŒ í…ŒìŠ¤íŠ¸ í›ˆë ¨ ì‹¤íŒ¨')
"
```

## ğŸ“ ìµœì¢… ë„ì›€ë§

### ëª¨ë“  ê²ƒì´ ì˜ ì•ˆ ë˜ë©´...
```bash
# ëª¨ë“  ì„¤ì •ì„ ìµœì†Œë¡œ ì¤„ì—¬ì„œ í…ŒìŠ¤íŠ¸
python -c "
config = '''# Ultra minimal config
seed: 42
__set_seed: !apply:torch.manual_seed [!ref <seed>]

data_folder: ./data  
output_folder: ./results
save_folder: !ref <output_folder>/save
train_json: !ref <data_folder>/train_data.json
val_json: !ref <data_folder>/val_data.json
test_json: !ref <data_folder>/eval.json
phoneme_map: !ref <data_folder>/phoneme_to_id.json

number_of_epochs: 1
batch_size: 1
eval_batch_size: 1
lr: 0.001
lr_wav2vec: 0.001

hidden_dim: 128
num_phonemes: 43
num_error_types: 3
use_cross_attention: False

wav2vec2_hub: facebook/wav2vec2-base
wav2vec2_freeze: True

sample_rate: 16000
max_audio_length: 80000

error_weight: 1.0
phoneme_weight: 1.0
task: both

grad_clipping: 1.0
weight_decay: 0.01
dropout: 0.1

evaluate_every_epoch: False
show_samples: False
num_sample_show: 1

num_workers: 0
pin_memory: False
persistent_workers: False

adam_opt_class: !name:torch.optim.AdamW
    lr: !ref <lr>
    weight_decay: !ref <weight_decay>

wav2vec_opt_class: !name:torch.optim.AdamW
    lr: !ref <lr_wav2vec>
    weight_decay: !ref <weight_decay>

lr_annealing: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau
    factor: 0.8
    patience: 2

error_stats: !name:speechbrain.utils.metric_stats.ErrorRateStats
phoneme_stats: !name:speechbrain.utils.metric_stats.ErrorRateStats

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        counter: !ref <epoch_counter>

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

train_dataloader_opts:
    batch_size: !ref <batch_size>
    shuffle: True
    num_workers: !ref <num_workers>
    pin_memory: !ref <pin_memory>
    persistent_workers: !ref <persistent_workers>

val_dataloader_opts:
    batch_size: !ref <eval_batch_size>
    shuffle: False
    num_workers: !ref <num_workers>
    pin_memory: !ref <pin_memory>
    persistent_workers: !ref <persistent_workers>

test_dataloader_opts:
    batch_size: !ref <eval_batch_size>
    shuffle: False
    num_workers: !ref <num_workers>
    pin_memory: !ref <pin_memory>
    persistent_workers: !ref <persistent_workers>
'''
with open('hparams/emergency.yaml', 'w') as f: f.write(config)
print('ğŸ†˜ ë¹„ìƒìš© ìµœì†Œ ì„¤ì • ìƒì„±: hparams/emergency.yaml')
"

# ë¹„ìƒìš© ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
python train.py hparams/emergency.yaml --data_folder ./data --output_folder ./emergency_results --device cuda
```

---

## ğŸ‰ ì´ì œ ì™„ì „íˆ ì‘ë™í•©ë‹ˆë‹¤!

**ëª¨ë“  SpeechBrain í´ë˜ìŠ¤ ê²½ë¡œ ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆê³ , src í´ë” ì—†ì´ ê¹”ë”í•œ êµ¬ì¡°ë¡œ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

### ğŸš€ ë°”ë¡œ ì‹œì‘:
```bash
python train.py hparams/multitask.yaml --data_folder ./data --output_folder ./results --device cuda
```

**Happy Training! ğŸµâœ¨**