data_folder: ./data
output_folder: ./results
train_json: !ref <data_folder>/train_data.json
valid_json: !ref <data_folder>/val_data.json
test_json: !ref <data_folder>/eval.json

task: both

number_of_epochs: 30
batch_size: 16
lr: 0.0003
lr_wav2vec: 0.00001
weight_decay: 0.01
phoneme_weight: 1.0
error_weight: 0.5

sample_rate: 16000
sorting: ascending
gradient_accumulation: 1
max_grad_norm: 1.0

wav2vec2_model: facebook/wav2vec2-base
hidden_dim: 768

blank_index: 0

train_dataloader_opts:
  batch_size: !ref <batch_size>
  shuffle: !ref <sorting> == "random"
  num_workers: 1

valid_dataloader_opts:
  batch_size: !ref <batch_size>
  shuffle: False
  num_workers: 1

test_dataloader_opts:
  batch_size: !ref <batch_size>
  shuffle: False
  num_workers: 1

precision: fp32
auto_mix_prec: False

ctc_cost: !name:speechbrain.nnet.losses.ctc_loss
    blank_index: !ref <blank_index>
    reduction: "mean"

wav2vec_opt_class: !name:torch.optim.AdamW
  lr: !ref <lr_wav2vec>
  weight_decay: !ref <weight_decay>

adam_opt_class: !name:torch.optim.AdamW
  lr: !ref <lr>
  weight_decay: !ref <weight_decay>